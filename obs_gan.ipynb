{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719770809.126435 2642041 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'PPO', 'learning_rate': 0.00025, 'num_envs': 4, 'num_steps': 128, 'total_timesteps': 100000.0, 'update_epochs': 4, 'num_minibatches': 4, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_eps': 0.2, 'ent_coef': 0.01, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'activation': 'tanh', 'anneal_lr': True, 'seed': 0, 'env_name': 'SimpleGridWorld-v0', 'env_kwargs': {'grid_size': 5, 'max_steps_in_episode': 20}, 'wandb_entity': 'drcope', 'wandb_project': 'ppo-gridworld-example', 'wandb_mode': 'online', 'output_dir': PosixPath('outputs/2024-06-14/15-39-35'), 'num_updates': 195.0, 'minibatch_size': 128}\n",
      "Loaded policy checkpoint.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "\n",
    "\n",
    "from poclaps.train.ckpt_cb import load_ckpt\n",
    "from poclaps.train.ppo import make_train as make_ppo_train\n",
    "from poclaps.train.ppo import FlattenObservationWrapper, LogWrapper\n",
    "from poclaps import environments\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "\n",
    "run_dir = Path('outputs/2024-06-14/15-39-35/')\n",
    "\n",
    "\n",
    "def load_config(run_dir):\n",
    "    with open(f'{run_dir}/.hydra/config.yaml') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "        config['output_dir'] = run_dir\n",
    "    return config\n",
    "\n",
    "config = load_config(run_dir)\n",
    "\n",
    "init_state, train_fn = make_ppo_train(config)\n",
    "\n",
    "print(config)\n",
    "\n",
    "def load_pretrained_policy(run_dir, config, ckpt_step=195):\n",
    "    init_state, _ = make_ppo_train(config)\n",
    "    ckpt = load_ckpt(run_dir / 'checkpoints', ckpt_step, init_state)\n",
    "    train_state, *_ = ckpt\n",
    "\n",
    "    def pretrained_policy(obs):\n",
    "        return train_state.apply_fn(train_state.vars, obs)\n",
    "\n",
    "    return pretrained_policy\n",
    "\n",
    "pretrained_policy = load_pretrained_policy(run_dir, config)\n",
    "print('Loaded policy checkpoint.')\n",
    "\n",
    "env, env_params = environments.make(config[\"env_name\"],\n",
    "                                    **config.get('env_kwargs', {}))\n",
    "env = FlattenObservationWrapper(env)\n",
    "env = LogWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poclaps.simple_gridworld_game import (\n",
    "    EnvState as SimpleGridWorldEnvState,\n",
    "    Envvars as SimpleGridWorldEnvParams,\n",
    ")\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import struct\n",
    "from chex import Array\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    env_state: struct.PyTreeNode\n",
    "    done: Array\n",
    "    action: Array\n",
    "    message: Array\n",
    "    reward: Array\n",
    "    log_prob: Array\n",
    "    obs: Array\n",
    "    info: dict\n",
    "    episode_id: int\n",
    "\n",
    "\n",
    "class SimpleGridWorldCommPolicy:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seed: int, env_params: SimpleGridWorldEnvParams):\n",
    "        self.seed = seed\n",
    "        self.env_params = env_params\n",
    "        self.n_msgs = env_params.grid_size * env_params.grid_size\n",
    "        grid_indices = list(range(self.n_msgs))\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(grid_indices)\n",
    "        self.msg_map = dict(enumerate(grid_indices))\n",
    "        self.mapping = jnp.array(list(self.msg_map.values()))\n",
    "\n",
    "    def get_msg(self, goal_pos: jnp.array) -> int:\n",
    "        pos_idx = goal_pos[0] * self.env_params.grid_size + goal_pos[1]\n",
    "        return self.mapping[pos_idx]\n",
    "\n",
    "comm_policy = SimpleGridWorldCommPolicy(0, env_params)\n",
    "\n",
    "\n",
    "def rollout_with_msgs(env, policy, comm_policy, steps, n_envs=4, rng=None, rollout_state=None):\n",
    "\n",
    "    @jax.jit\n",
    "    def _env_step(rollout_state, _):\n",
    "        env_state, last_obs, rng, ep_ids = rollout_state\n",
    "\n",
    "        # SELECT ACTION\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        pi, _ = policy(last_obs)\n",
    "        action = pi.sample(seed=_rng)\n",
    "        log_prob = pi.log_prob(action)\n",
    "\n",
    "        # STEP ENV\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        rng_step = jax.random.split(_rng, n_envs)\n",
    "        obsv, env_state, reward, done, info = jax.vmap(\n",
    "            env.step, in_axes=(0, 0, 0, None)\n",
    "        )(rng_step, env_state, action, env_params)\n",
    "        ep_ids = jnp.where(done, ep_ids + n_envs, ep_ids)\n",
    "\n",
    "        msg = jax.lax.map(\n",
    "            lambda g: comm_policy.get_msg(g),\n",
    "            env_state.env_state.goal_pos\n",
    "        )\n",
    "\n",
    "        transition = Transition(\n",
    "            env_state, done, action, msg, reward, log_prob, last_obs, info, ep_ids\n",
    "        )\n",
    "        rollout_state = (env_state, obsv, rng, ep_ids)\n",
    "        return rollout_state, transition\n",
    "\n",
    "    if rollout_state is None:\n",
    "        if rng is None:\n",
    "            rng = jax.random.PRNGKey(0)\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        reset_rng = jax.random.split(_rng, n_envs)\n",
    "        obsv, env_state = jax.vmap(env.reset,\n",
    "                                   in_axes=(0, None))(reset_rng, env_params)\n",
    "        ep_ids = jnp.arange(n_envs)\n",
    "        rollout_state = (env_state, obsv, rng, ep_ids)\n",
    "\n",
    "    rollout_state, traj_batch = jax.lax.scan(\n",
    "        _env_step, rollout_state, None, steps\n",
    "    )\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    metrics['mean_reward'] = (\n",
    "        (traj_batch.info[\"returned_episode_returns\"] * traj_batch.info[\"returned_episode\"]).sum()\n",
    "        / traj_batch.info[\"returned_episode\"].sum()\n",
    "    )\n",
    "\n",
    "    metrics['mean_episode_len'] = (\n",
    "        (traj_batch.info[\"returned_episode_lengths\"] * traj_batch.info[\"returned_episode\"]).sum()\n",
    "        / traj_batch.info[\"returned_episode\"].sum()\n",
    "    )\n",
    "\n",
    "    metrics['n_episodes'] = traj_batch.info[\"returned_episode\"].sum()\n",
    "\n",
    "    return rollout_state, traj_batch, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax\n",
    "import functools\n",
    "\n",
    "\n",
    "class ScannedRNN(nn.Module):\n",
    "    hidden_size: int = 128\n",
    "\n",
    "    @functools.partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"vars\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"Applies the module.\"\"\"\n",
    "        rnn_state = carry\n",
    "        ins, resets = x\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, np.newaxis],\n",
    "            self.initialize_carry(*rnn_state.shape),\n",
    "            rnn_state,\n",
    "        )\n",
    "        new_rnn_state, y = nn.GRUCell(features=self.hidden_size)(rnn_state, ins)\n",
    "        return new_rnn_state, y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(n_envs, hidden_size):\n",
    "        # Use a dummy key since the default state init fn is just zeros.\n",
    "        cell = nn.GRUCell(features=hidden_size)\n",
    "        return cell.initialize_carry(jax.random.PRNGKey(0), (n_envs, hidden_size))\n",
    "\n",
    "\n",
    "class ScannedBiRNN(nn.Module):\n",
    "    hidden_size: int = 128\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, inputs):\n",
    "        forward_carry, backward_carry = carry\n",
    "        forward_carry, forward_embs = ScannedRNN(self.hidden_size)(\n",
    "            forward_carry, inputs\n",
    "        )\n",
    "        feats, resets = inputs\n",
    "        backward_inputs = (feats[::-1], resets[::-1])\n",
    "        backward_carry, backward_embs = ScannedRNN(self.hidden_size)(\n",
    "            backward_carry, backward_inputs\n",
    "        )\n",
    "        carry = (forward_carry, backward_carry)\n",
    "        embs = jnp.concatenate([forward_embs, backward_embs], axis=-1)\n",
    "        return carry, embs\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(n_envs, hidden_size):\n",
    "        return (\n",
    "            ScannedRNN.initialize_carry(n_envs, hidden_size),\n",
    "            ScannedRNN.initialize_carry(n_envs, hidden_size)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObsModel(nn.Module):\n",
    "    obs_size: int\n",
    "    hidden_size: int = 128\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, inputs: tuple, train: bool=False):\n",
    "        _, noise = inputs\n",
    "        # feats = jnp.concatenate([actions, messages, noise], axis=-1)\n",
    "        feats = noise\n",
    "        # *_, dones, obs = inputs\n",
    "        # feats = obs\n",
    "\n",
    "        x = nn.Dense(self.hidden_size)(feats)\n",
    "        x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "\n",
    "        # _, n_envs, _ = x.shape\n",
    "        # carry = ScannedBiRNN.initialize_carry(n_envs, self.hidden_size)\n",
    "        # bi_lstm = ScannedBiRNN(self.hidden_size)\n",
    "        # _, x = bi_lstm(carry, (x, dones))\n",
    "\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.BatchNorm(use_running_average=not train)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "\n",
    "        obs_preds = nn.Dense(self.obs_size)(x)\n",
    "        obs_preds = nn.sigmoid(obs_preds)\n",
    "        return obs_preds\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    hidden_size: int = 128\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, tuple):\n",
    "            x, *_ = x\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        # x = nn.Dropout(0.3)(x)\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        # x = nn.Dropout(0.3)(x)\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        # x = nn.Dropout(0.3)(x)\n",
    "        x = nn.Dense(self.hidden_size)(x)\n",
    "        x = nn.leaky_relu(x)\n",
    "        # x = nn.Dropout(0.3)(x)\n",
    "        y = nn.Dense(1)(x)\n",
    "        return y.squeeze()\n",
    "\n",
    "\n",
    "N_ACTIONS = env.action_space(env_params).n\n",
    "\n",
    "def sample_obs_modelling_batch(rng,\n",
    "                               noise_dim: int = 64,\n",
    "                               rollout_steps: int = 500,\n",
    "                               return_traj: bool = False):\n",
    "    rng, rollout_rng = jax.random.split(rng)\n",
    "    _, traj_batch, metrics = rollout_with_msgs(\n",
    "        env, pretrained_policy, comm_policy,\n",
    "        steps=rollout_steps,\n",
    "        rng=rollout_rng\n",
    "    )\n",
    "\n",
    "    *batch_shape, _ = traj_batch.obs.shape\n",
    "    batch_dim = np.prod(batch_shape)\n",
    "    obs_dim = traj_batch.obs.shape[-1]\n",
    "    obs = traj_batch.obs.reshape((batch_dim, obs_dim))\n",
    "    noise = jax.random.normal(rng, (batch_dim, noise_dim))\n",
    "    inputs = (noise, obs)\n",
    "    if return_traj:\n",
    "        return inputs, metrics, traj_batch\n",
    "    return inputs, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "obs_space = env.observation_space(env_params)\n",
    "obs_size = obs_space.shape[0]\n",
    "discriminator = Discriminator(4 * hidden_size)\n",
    "obs_model = ObsModel(obs_size, 4 * hidden_size)\n",
    "\n",
    "\n",
    "from typing import Any, Tuple, Callable\n",
    "from flax import core\n",
    "from flax import struct\n",
    "import optax\n",
    "from optax.losses import sigmoid_binary_cross_entropy\n",
    "\n",
    "from poclaps.train.training_cb import TrainerCallback\n",
    "\n",
    "\n",
    "def create_discriminator_sample(obs_model_vars, batch_inputs):\n",
    "    # compute obs preds\n",
    "    *_, obs = batch_inputs\n",
    "    batch_size, _ = obs.shape\n",
    "    # batch_size = steps * n_envs\n",
    "    obs_preds = obs_model.apply(obs_model_vars, batch_inputs)\n",
    "    # obs_preds = obs_preds.reshape((batch_size, obs_dim))\n",
    "    # obs_batch = obs.reshape((batch_size, obs_dim))\n",
    "\n",
    "    # compute inputs and labels\n",
    "    labels = jnp.concatenate([jnp.ones(batch_size),\n",
    "                              jnp.zeros(batch_size)])\n",
    "    obs_inputs = jnp.concatenate([obs, obs_preds], axis=0)\n",
    "\n",
    "    return obs_inputs, labels\n",
    "\n",
    "\n",
    "def compute_discriminator_loss(model_vars, inputs):\n",
    "    discriminator_vars, obs_model_vars = model_vars\n",
    "    obs_inputs, labels = create_discriminator_sample(obs_model_vars, inputs)\n",
    "    label_pred = discriminator.apply(discriminator_vars, obs_inputs)\n",
    "    return sigmoid_binary_cross_entropy(label_pred, labels).mean()\n",
    "\n",
    "\n",
    "def compute_adv_obs_model_loss(model_vars, inputs):\n",
    "    discriminator_vars, obs_model_vars = model_vars\n",
    "\n",
    "    # # compute action preds loss\n",
    "    obs_preds, updates = obs_model.apply(\n",
    "        obs_model_vars, inputs, train=True,\n",
    "        mutable=['batch_stats']\n",
    "    )\n",
    "    # pred_action_dist, _ = pretrained_policy(obs_preds)\n",
    "    # actions, *_ = inputs\n",
    "    # act_pred_loss = categorical_cross_entropy(\n",
    "    #     pred_action_dist.logits, actions\n",
    "    # ).mean()\n",
    "\n",
    "    # compute adversarial loss\n",
    "    discr_pred = discriminator.apply(\n",
    "        discriminator_vars, obs_preds\n",
    "    )\n",
    "    discr_labels = jnp.ones_like(discr_pred)\n",
    "    adv_loss = sigmoid_binary_cross_entropy(\n",
    "        discr_pred, discr_labels\n",
    "    ).mean()\n",
    "\n",
    "    adv_factor = 1.0\n",
    "\n",
    "    # return act_pred_loss + adv_factor * adv_loss\n",
    "    return adv_factor * adv_loss, updates['batch_stats']\n",
    "\n",
    "\n",
    "class AdvObsModellingTrainState(struct.PyTreeNode):\n",
    "    step: int\n",
    "    rng: jnp.ndarray\n",
    "    tx: optax.GradientTransformation = struct.field(pytree_node=False)\n",
    "\n",
    "    # obs model\n",
    "    obs_model_apply_fn: Callable = struct.field(pytree_node=False)\n",
    "    obs_model_vars: core.FrozenDict[str, Any] = struct.field(pytree_node=True)\n",
    "    obs_model_opt_state: optax.OptState = struct.field(pytree_node=True)\n",
    "\n",
    "    # discriminator\n",
    "    discriminator_apply_fn: Callable = struct.field(pytree_node=False)\n",
    "    discriminator_vars: core.FrozenDict[str, Any] = struct.field(pytree_node=True)\n",
    "    discriminator_opt_state: optax.OptState = struct.field(pytree_node=True)\n",
    "\n",
    "\n",
    "class AdversarialObsModellingTrainer:\n",
    "\n",
    "    def __init__(self,\n",
    "                 obs_model: ObsModel,\n",
    "                 discriminator: Discriminator,\n",
    "                 config: dict,\n",
    "                 callback: TrainerCallback = None):\n",
    "        self.obs_model = obs_model\n",
    "        self.discriminator = discriminator\n",
    "        self.callback = callback or TrainerCallback()\n",
    "        self.config = config\n",
    "\n",
    "        if 'seed' not in config:\n",
    "            self.config['seed'] = 0\n",
    "        if 'learning_rate' not in config:\n",
    "            self.config['learning_rate'] = 1e-3\n",
    "        if 'discriminator_updates_per_step' not in config:\n",
    "            self.config['discriminator_updates_per_step'] = 1\n",
    "        if 'obs_model_updates_per_step' not in config:\n",
    "            self.config['obs_model_updates_per_step'] = 1\n",
    "\n",
    "    def update_obs_model(self, tx, opt_state, model_vars, inputs):\n",
    "        _, obs_model_vars = model_vars\n",
    "        grad_fn = jax.value_and_grad(compute_adv_obs_model_loss, has_aux=True)\n",
    "        (loss, batch_stats), (_, grad) = grad_fn(model_vars, inputs)\n",
    "        updates, new_opt_state = tx.update(grad, opt_state)\n",
    "        new_params = optax.apply_updates(obs_model_vars['params'], updates['params'])\n",
    "        new_variables = {'params': new_params, 'batch_stats': batch_stats}\n",
    "        return loss, new_variables, new_opt_state\n",
    "\n",
    "    def update_discriminator(self, tx, opt_state, model_vars, inputs):\n",
    "        discriminator_vars, _ = model_vars\n",
    "        grad_fn = jax.value_and_grad(compute_discriminator_loss)\n",
    "        loss, (grad, _) = grad_fn(model_vars, inputs)\n",
    "        updates, new_opt_state = tx.update(grad, opt_state)\n",
    "        new_variables = optax.apply_updates(discriminator_vars, updates)\n",
    "        return loss, new_variables, new_opt_state\n",
    "\n",
    "    def train_step(self, train_state: AdvObsModellingTrainState) -> AdvObsModellingTrainState:\n",
    "        rng, _rng = jax.random.split(train_state.rng)\n",
    "        inputs, metrics = sample_obs_modelling_batch(_rng)\n",
    "\n",
    "        metrics = {\n",
    "            f'sample/{k}': v for k, v in metrics.items()\n",
    "        }\n",
    "\n",
    "        def run_obs_model_substep(substep_state, _):\n",
    "            obs_model_vars, opt_state = substep_state\n",
    "            model_vars = (train_state.discriminator_vars, obs_model_vars)\n",
    "            loss, new_params, new_opt_state = self.update_obs_model(\n",
    "                train_state.tx, opt_state, model_vars, inputs\n",
    "            )\n",
    "            return (new_params, new_opt_state), loss\n",
    "        \n",
    "        (new_obs_model_vars, new_obs_model_opt_state), obs_model_loss = jax.lax.scan(\n",
    "            run_obs_model_substep,\n",
    "            (train_state.obs_model_vars, train_state.obs_model_opt_state),\n",
    "            None,\n",
    "            self.config['obs_model_updates_per_step']\n",
    "        )\n",
    "        metrics['train/obs_model_loss'] = obs_model_loss.mean()\n",
    "\n",
    "        def run_discriminator_substep(substep_state, _):\n",
    "            discr_vars, opt_state = substep_state\n",
    "            model_vars = (discr_vars, train_state.obs_model_vars)\n",
    "            loss, new_discr_vars, new_opt_state = self.update_discriminator(\n",
    "                train_state.tx, opt_state, model_vars, inputs\n",
    "            )\n",
    "            return (new_discr_vars, new_opt_state), loss\n",
    "\n",
    "        (new_discr_vars, new_discr_opt_state), discr_loss = jax.lax.scan(\n",
    "            run_discriminator_substep,\n",
    "            (train_state.discriminator_vars, train_state.discriminator_opt_state),\n",
    "            None,\n",
    "            self.config['discriminator_updates_per_step']\n",
    "        )\n",
    "        metrics['train/discriminator_loss'] = discr_loss.mean()\n",
    "\n",
    "        new_params = (new_discr_vars, new_obs_model_vars)\n",
    "        metrics.update(self.compute_eval_metrics(new_params, inputs))\n",
    "\n",
    "        jax.experimental.io_callback(\n",
    "            self.callback.on_iteration_end, None,\n",
    "            train_state.step, train_state, metrics\n",
    "        )\n",
    "\n",
    "        train_state = train_state.replace(\n",
    "            rng=rng,\n",
    "            step=train_state.step + 1,\n",
    "            obs_model_vars=new_obs_model_vars,\n",
    "            obs_model_opt_state=new_obs_model_opt_state,\n",
    "            discriminator_vars=new_discr_vars,\n",
    "            discriminator_opt_state=new_discr_opt_state\n",
    "        )\n",
    "\n",
    "        return train_state, metrics\n",
    "\n",
    "    def compute_eval_metrics(self, model_vars: tuple, inputs: tuple) -> dict:\n",
    "        eval_metrics = {}\n",
    "\n",
    "        discr_vars, obs_model_vars = model_vars\n",
    "        \n",
    "        obs_preds = self.obs_model.apply(obs_model_vars, inputs)\n",
    "        mean_var = jnp.mean(jnp.var(obs_preds, axis=0))\n",
    "        eval_metrics['eval/obs_pred_var'] = mean_var\n",
    "\n",
    "        # noise, obs = inputs\n",
    "        # eval_metrics['eval/obs_pred_err'] = jnp.square(obs_preds - obs).mean()\n",
    "\n",
    "        # pred_action_dist, _ = pretrained_policy(obs_preds)\n",
    "        # eval_metrics['eval/action_pred_acc'] = (\n",
    "        #     (pred_action_dist.probs.argmax(axis=-1) == actions.argmax(axis=-1)).mean()\n",
    "        # )\n",
    "\n",
    "        obs_inputs, labels = create_discriminator_sample(obs_model_vars, inputs)\n",
    "        label_pred = self.discriminator.apply(discr_vars, obs_inputs)\n",
    "        eval_metrics['eval/discr_acc'] = (\n",
    "            ((label_pred > 0) == labels).mean()\n",
    "        )\n",
    "\n",
    "        return eval_metrics\n",
    "\n",
    "    def train(self, n_steps: int) -> Tuple[AdvObsModellingTrainState, dict]:\n",
    "        optimizer = optax.adam(self.config['learning_rate'])\n",
    "        rng = jax.random.PRNGKey(self.config['seed'])\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        inputs, _ = sample_obs_modelling_batch(_rng)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        obs_model_vars = self.obs_model.init(_rng, inputs, train=False)\n",
    "        obs_model_opt_state = optimizer.init(obs_model_vars)\n",
    "\n",
    "        rng, _rng = jax.random.split(rng)\n",
    "        discr_inp, *_ = create_discriminator_sample(obs_model_vars, inputs)\n",
    "        discr_vars = self.discriminator.init(_rng, discr_inp)\n",
    "        discr_opt_state = optimizer.init(discr_vars)\n",
    "\n",
    "        init_train_state = AdvObsModellingTrainState(\n",
    "            step=0,\n",
    "            rng=rng,\n",
    "            tx=optimizer,\n",
    "            obs_model_apply_fn=self.obs_model.apply,\n",
    "            obs_model_vars=obs_model_vars,\n",
    "            obs_model_opt_state=obs_model_opt_state,\n",
    "            discriminator_apply_fn=self.discriminator.apply,\n",
    "            discriminator_vars=discr_vars,\n",
    "            discriminator_opt_state=discr_opt_state,\n",
    "        )\n",
    "\n",
    "        self.callback.on_train_begin(self.config)\n",
    "\n",
    "        try:\n",
    "            train_results = jax.lax.scan(\n",
    "                jax.jit(lambda s, _: self.train_step(s)),\n",
    "                init_train_state, None, n_steps\n",
    "            )\n",
    "        finally:\n",
    "            self.callback.on_train_end(None)\n",
    "\n",
    "        return train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poclaps.train.wandb_cb import WandbCallback\n",
    "\n",
    "\n",
    "cb = WandbCallback(['OBS-GAN'])\n",
    "config = {\n",
    "    'seed': 0,\n",
    "    'learning_rate': 1e-4,\n",
    "    'discriminator_updates_per_step': 1,\n",
    "    'obs_model_updates_per_step': 1,\n",
    "    'wandb_entity': 'drcope',\n",
    "    'wandb_project': 'poclaps-obs-modelling',\n",
    "    'wandb_mode': 'online',\n",
    "}\n",
    "aom_trainer = AdversarialObsModellingTrainer(obs_model, discriminator, config, cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to wandb using secrets/wandb_api_key.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nas/ucb/dylancope/poclaps/wandb/run-20240630_132319-9156j3du</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drcope/poclaps-obs-modelling/runs/9156j3du' target=\"_blank\">comic-wind-22</a></strong> to <a href='https://wandb.ai/drcope/poclaps-obs-modelling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drcope/poclaps-obs-modelling' target=\"_blank\">https://wandb.ai/drcope/poclaps-obs-modelling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drcope/poclaps-obs-modelling/runs/9156j3du' target=\"_blank\">https://wandb.ai/drcope/poclaps-obs-modelling/runs/9156j3du</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164e9538854543d1b8ea9672731cd7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.015 MB of 0.015 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/discr_acc</td><td>██▃█▇▆▆▅▄▄▄▄▃▄▃▂▃▃▂▂▂▂▃▂▃▄▃▂▁▂▂▂▁▃▃▂▂▃▂▂</td></tr><tr><td>eval/obs_pred_var</td><td>▁▄▃▃▅▆▇▇▇▇▇█▇▇███▇███▇█▇█▇█▇▇▇█▇▇▇▇▇█▇██</td></tr><tr><td>sample/mean_episode_len</td><td>▆▃▅▄▅▄▆▅▅▆▂▃▆▄▃▄▂▃▄▁▅▄▆▄▅▄▅▄▆▄█▆▄▄▆▄▅▄▄▄</td></tr><tr><td>sample/mean_reward</td><td>▃▆▄▅▄▅▃▄▄▃▇▆▃▅▆▅▇▆▅█▄▅▃▅▄▅▄▅▃▅▁▃▅▅▃▅▄▅▅▅</td></tr><tr><td>sample/n_episodes</td><td>▂▆▄▅▄▅▃▄▄▃▇▅▃▅▆▅█▆▅█▃▅▂▅▄▄▃▅▂▅▁▃▅▅▃▅▄▄▅▄</td></tr><tr><td>train/discriminator_loss</td><td>▁▁▇▁▃▃▄▅▅▆▆▅▇▆▇▇▇▆█▇█▇▇▆▇▅▇██▇▇▇█▇▇█▇▆█▇</td></tr><tr><td>train/obs_model_loss</td><td>▁▁▄▇███▇█▇▇▇█▇▇▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/discr_acc</td><td>0.96275</td></tr><tr><td>eval/obs_pred_var</td><td>0.09643</td></tr><tr><td>sample/mean_episode_len</td><td>3.36195</td></tr><tr><td>sample/mean_reward</td><td>-1.36195</td></tr><tr><td>sample/n_episodes</td><td>594</td></tr><tr><td>train/discriminator_loss</td><td>0.1027</td></tr><tr><td>train/obs_model_loss</td><td>5.17709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">comic-wind-22</strong> at: <a href='https://wandb.ai/drcope/poclaps-obs-modelling/runs/9156j3du' target=\"_blank\">https://wandb.ai/drcope/poclaps-obs-modelling/runs/9156j3du</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240630_132319-9156j3du/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state, metrics = aom_trainer.train(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, _ = sample_obs_modelling_batch(jax.random.PRNGKey(0))\n",
    "obs_preds = obs_model.apply(train_state.obs_model_vars, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[4, 2],\n",
       "        [3, 0]],\n",
       "\n",
       "       [[4, 2],\n",
       "        [0, 4]],\n",
       "\n",
       "       [[3, 2],\n",
       "        [0, 2]],\n",
       "\n",
       "       [[4, 2],\n",
       "        [1, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_preds[:4].reshape((-1, 2, 2, 5)).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0, 4],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[2, 3],\n",
       "        [2, 3]],\n",
       "\n",
       "       [[2, 4],\n",
       "        [0, 3]]], dtype=int32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise, obs = inputs\n",
    "obs[:3].reshape((-1, 2, 2, 5)).argmax(axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
